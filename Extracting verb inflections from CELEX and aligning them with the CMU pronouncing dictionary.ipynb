{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.068711Z",
     "start_time": "2019-05-17T01:11:26.065882Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook author:** emeinhardt@ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span><ul class=\"toc-item\"><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Requirements</a></span></li></ul></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Loading-and-Parsing-CELEX-emw\" data-toc-modified-id=\"Loading-and-Parsing-CELEX-emw-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Loading and Parsing CELEX <code>emw</code></a></span></li><li><span><a href=\"#Filtering-it-for-wordforms-with-inflections-of-interest\" data-toc-modified-id=\"Filtering-it-for-wordforms-with-inflections-of-interest-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Filtering it for wordforms with inflections of interest</a></span></li><li><span><a href=\"#Filtering-emw-for-just-those-lemmas-with-all-inflections-of-interest\" data-toc-modified-id=\"Filtering-emw-for-just-those-lemmas-with-all-inflections-of-interest-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Filtering <code>emw</code> for just those lemmas with <em>all</em> inflections of interest</a></span></li><li><span><a href=\"#Create-tsv-file-with-rows-of-interest\" data-toc-modified-id=\"Create-tsv-file-with-rows-of-interest-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Create <code>tsv</code> file with rows of interest</a></span></li><li><span><a href=\"#Substituting-orthographic-forms-for-transcriptions-from-the-CMU-pronouncing-dictionary\" data-toc-modified-id=\"Substituting-orthographic-forms-for-transcriptions-from-the-CMU-pronouncing-dictionary-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Substituting orthographic forms for transcriptions from the CMU pronouncing dictionary</a></span></li><li><span><a href=\"#Aligning-the-(orthographic)-morphological-database-with-the-CMU-dictionary\" data-toc-modified-id=\"Aligning-the-(orthographic)-morphological-database-with-the-CMU-dictionary-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Aligning the (orthographic) morphological database with the CMU dictionary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is producing a tab-separated value file where each row contains phonemic transcriptions of \n",
    " - the first person present\n",
    " - the third person present\n",
    " - the first person past\n",
    " - the third person past\n",
    "\n",
    "inflected wordforms for a single English verb.\n",
    "\n",
    "The file is produced by reading in data from the CELEX-2 database for English morphological wordforms, and then mapping the orthographic transcriptions of each inflected wordform to transcriptions from the CMU pronouncing dictionary. The CELEX data is not included in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - As noted above, you must have (and further below, correctly set the filepath for) the CELEX database.\n",
    " - The notebook makes use of shell command magics for Unix-like systems (though none of these calls are essential).\n",
    " - The notebook makes use of `joblib` for parallelizing data processing. In each case, commented-out code in the same cell that does not require joblib is also present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.116785Z",
     "start_time": "2019-05-17T01:11:26.074749Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "union = lambda Ss: reduce(set.union, Ss)\n",
    "\n",
    "from itertools import chain, zip_longest, compress\n",
    "\n",
    "# from https://docs.python.org/3/library/itertools.html#itertools-recipes\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "from os import getcwd, chdir, listdir, mkdir, makedirs, path\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.124748Z",
     "start_time": "2019-05-17T01:11:26.118974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cube/home/AD/emeinhar/english-verbs'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_dir = getcwd(); repo_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.133602Z",
     "start_time": "2019-05-17T01:11:26.126281Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed, Memory\n",
    "\n",
    "J = -1\n",
    "BACKEND = 'multiprocessing'\n",
    "# BACKEND = 'loky'\n",
    "V = 10\n",
    "PREFER = 'processes'\n",
    "# PREFER = 'threads'\n",
    "\n",
    "def par(gen_expr, j=None, backend=None, verbose=None, prefer=None):\n",
    "    if j is None:\n",
    "        j = J\n",
    "    if backend is None:\n",
    "        backend = BACKEND\n",
    "    if verbose is None:\n",
    "        verbose = V\n",
    "    if prefer is None:\n",
    "        prefer = PREFER\n",
    "    return Parallel(n_jobs=j, backend=backend, verbose=verbose, prefer=prefer)(gen_expr)\n",
    "\n",
    "def identity(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Parsing CELEX `emw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.139974Z",
     "start_time": "2019-05-17T01:11:26.135904Z"
    }
   },
   "outputs": [],
   "source": [
    "CELEX_dir = '/mnt/cube/home/AD/emeinhar/celex-2'\n",
    "chdir(CELEX_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.145896Z",
     "start_time": "2019-05-17T01:11:26.142191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['english',\n",
       " 'intro_le.ps',\n",
       " 'c',\n",
       " 'dutch',\n",
       " 'intro_a4.ps',\n",
       " 'intro_let.pdf',\n",
       " 'intro_a4.pdf',\n",
       " 'awk',\n",
       " 'german',\n",
       " 'README']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.151568Z",
     "start_time": "2019-05-17T01:11:26.147512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ect',\n",
       " 'efl',\n",
       " 'emw',\n",
       " 'eug_let.ps',\n",
       " 'eol',\n",
       " 'epl',\n",
       " 'epw',\n",
       " 'eow',\n",
       " 'esl',\n",
       " 'efs',\n",
       " 'efw',\n",
       " 'eug_a4.ps',\n",
       " 'eml',\n",
       " 'readme.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chdir('english'); listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.267332Z",
     "start_time": "2019-05-17T01:11:26.153079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\tThis directory contains the subdirectories:\r\n",
      "     2\t\r\n",
      "     3\t         eol       English Orthography, Lemmas\r\n",
      "     4\t                       (filesize eol.cd:  2,068,262 bytes)\r\n",
      "     5\t         epl       English Phonology, Lemmas\r\n",
      "     6\t                       (filesize epl.cd:  5,480,381 bytes)\r\n",
      "     7\t         eml       English Morphology, Lemmas\r\n",
      "     8\t                       (filesize eml.cd:  4,918,610 bytes)\r\n",
      "     9\t         esl       English Syntax, Lemmas\r\n",
      "    10\t                       (filesize esl.cd:  5,560,364 bytes)\r\n",
      "    11\t         efl       English Frequency, Lemmas\r\n",
      "    12\t                       (filesize efl.cd:  2,143,469 bytes)\r\n",
      "    13\t\r\n",
      "    14\t         eow       English Orthography, Wordforms\r\n",
      "    15\t                       (filesize eow.cd:  7,351,883 bytes)\r\n",
      "    16\t         epw       English Phonology, Wordforms\r\n",
      "    17\t                       (filesize epw.cd: 15,567,897 bytes)\r\n",
      "    18\t         emw       English Morphology, Wordforms\r\n",
      "    19\t                       (filesize emf.cd:  4,936,327 bytes)\r\n",
      "    20\t         efw       English Frequency, Wordforms\r\n",
      "    21\t                       (filesize efw.cd:  7,158,616 bytes)\r\n",
      "    22\t\r\n",
      "    23\t         ect       English Corpus Types\r\n",
      "    24\t                       (filesize ect.cd: 5,861,603 bytes)\r\n",
      "    25\t         efs       English Frequency, Syllables\r\n",
      "    26\t                       (filesize efs.cd:   263,859 bytes)\r\n",
      "    27\t\r\n",
      "    28\tand the PostScript files of the CELEX User Guide on English, in both\r\n",
      "    29\tEuropean A4 (21c x 29.7c or 8.3 x 11.7 inches) and American letter\r\n",
      "    30\tformat (8.5 x 11 inches):\r\n",
      "    31\t                   \r\n",
      "    32\t           eug_a4.ps   (filesize eug_a4.ps:  833,906 bytes)\r\n",
      "    33\t           eug_let.ps  (filesize eug_let.ps: 783,453 bytes)\r\n"
     ]
    }
   ],
   "source": [
    "!cat -n readme. | head -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.274564Z",
     "start_time": "2019-05-17T01:11:26.269688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awk', 'emw.cd', 'readme.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('emw'); chdir('emw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.388535Z",
     "start_time": "2019-05-17T01:11:26.276230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\tENGLISH MORPHOLOGY, WORDFORMS\r\n",
      "     2\t\r\n",
      "     3\tThe emw.cd file contains the following fields:\r\n",
      "     4\t\r\n",
      "     5\t1.    IdNum\r\n",
      "     6\t2.    Word\r\n",
      "     7\t3.    Cob\r\n",
      "     8\t4.    IdNumLemma\r\n",
      "     9\t5.    FlectType\r\n",
      "    10\t6.    TransInfl\r\n",
      "    11\t\r\n",
      "    12\tThe awk directory contains the script\r\n",
      "    13\t\r\n",
      "    14\t   script TypeToInflectionalFeatures(String):    type2fea.awk\r\n",
      "    15\t\r\n",
      "    16\tfor reconstructing the 13 Inflectional Features fields outlined in the\r\n",
      "    17\tCELEX User Guide:\r\n",
      "    18\t\r\n",
      "    19\t   1. Sing\r\n",
      "    20\t   2. Plu\r\n",
      "    21\t   3. Pos\r\n",
      "    22\t   4. Comp\r\n",
      "    23\t   5. Sup\r\n",
      "    24\t   6. Inf\r\n",
      "    25\t   7. Part\r\n",
      "    26\t   8. Pres\r\n",
      "    27\t   9. Past\r\n",
      "    28\t  10. Sin1\r\n",
      "    29\t  11. Sin2\r\n",
      "    30\t  12. Sin3\r\n",
      "    31\t  13. Rare\r\n"
     ]
    }
   ],
   "source": [
    "!cat -n readme. | head -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.505620Z",
     "start_time": "2019-05-17T01:11:26.390901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t1\\a\\413887\\1\\X\\@\r\n",
      "     2\t2\\a\\422336\\2\\S\\@\r\n",
      "     3\t3\\A\\422334\\4\\X\\@\r\n",
      "     4\t4\\a\\8448\\3\\X\\@\r\n",
      "     5\t5\\AA\\52\\5\\S\\@\r\n",
      "     6\t6\\AA\\95\\6\\X\\@\r\n",
      "     7\t7\\AAs\\0\\5\\P\\@+s\r\n",
      "     8\t8\\abaci\\0\\8\\P\\\r\n",
      "     9\t9\\aback\\59\\7\\b\\@\r\n",
      "    10\t10\\abacus\\8\\8\\S\\@\r\n",
      "cat: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!cat -n emw.cd | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.823376Z",
     "start_time": "2019-05-17T01:11:26.508054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160595"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[['1', 'a', '413887', '1', 'X', '@'],\n",
       " ['2', 'a', '422336', '2', 'S', '@'],\n",
       " ['3', 'A', '422334', '4', 'X', '@'],\n",
       " ['4', 'a', '8448', '3', 'X', '@'],\n",
       " ['5', 'AA', '52', '5', 'S', '@'],\n",
       " ['6', 'AA', '95', '6', 'X', '@'],\n",
       " ['7', 'AAs', '0', '5', 'P', '@+s'],\n",
       " ['8', 'abaci', '0', '8', 'P'],\n",
       " ['9', 'aback', '59', '7', 'b', '@'],\n",
       " ['10', 'abacus', '8', '8', 'S', '@']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emw_lines = []\n",
    "with open(\"emw.cd\", 'r') as f:\n",
    "    for line in f:\n",
    "        split_line = [s for s in line.rstrip().split(\"\\\\\") if s != \"\"]\n",
    "        emw_lines.append(split_line)\n",
    "len(emw_lines)\n",
    "emw_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.826939Z",
     "start_time": "2019-05-17T01:11:26.824783Z"
    }
   },
   "outputs": [],
   "source": [
    "emw_fields = ('IdNum','Word','Cob','IdNumLemma','FlectType','TransInfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:26.841619Z",
     "start_time": "2019-05-17T01:11:26.829259Z"
    }
   },
   "outputs": [],
   "source": [
    "def parseEMWline(split_line):\n",
    "    entry = OrderedDict(zip(emw_fields, split_line))\n",
    "    for field in ('IdNum', 'Cob', 'IdNumLemma'):\n",
    "        entry[field] = int(entry[field])\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:27.327908Z",
     "start_time": "2019-05-17T01:11:26.843573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 456),\n",
       "              ('Word', 'accordance'),\n",
       "              ('Cob', 134),\n",
       "              ('IdNumLemma', 249),\n",
       "              ('FlectType', 'S'),\n",
       "              ('TransInfl', '@')]),\n",
       " OrderedDict([('IdNum', 457),\n",
       "              ('Word', 'accorded'),\n",
       "              ('Cob', 16),\n",
       "              ('IdNumLemma', 248),\n",
       "              ('FlectType', 'a1S'),\n",
       "              ('TransInfl', '@+ed')]),\n",
       " OrderedDict([('IdNum', 458),\n",
       "              ('Word', 'according'),\n",
       "              ('Cob', 1884),\n",
       "              ('IdNumLemma', 248),\n",
       "              ('FlectType', 'pe'),\n",
       "              ('TransInfl', '@+ing')]),\n",
       " OrderedDict([('IdNum', 459),\n",
       "              ('Word', 'according as'),\n",
       "              ('Cob', 0),\n",
       "              ('IdNumLemma', 250),\n",
       "              ('FlectType', 'X'),\n",
       "              ('TransInfl', '@ @')]),\n",
       " OrderedDict([('IdNum', 460),\n",
       "              ('Word', 'accordingly'),\n",
       "              ('Cob', 249),\n",
       "              ('IdNumLemma', 251),\n",
       "              ('FlectType', 'b'),\n",
       "              ('TransInfl', '@')]),\n",
       " OrderedDict([('IdNum', 461),\n",
       "              ('Word', 'according to'),\n",
       "              ('Cob', 0),\n",
       "              ('IdNumLemma', 252),\n",
       "              ('FlectType', 'X'),\n",
       "              ('TransInfl', '@ @')]),\n",
       " OrderedDict([('IdNum', 462),\n",
       "              ('Word', 'accordion'),\n",
       "              ('Cob', 15),\n",
       "              ('IdNumLemma', 253),\n",
       "              ('FlectType', 'S'),\n",
       "              ('TransInfl', '@')]),\n",
       " OrderedDict([('IdNum', 463),\n",
       "              ('Word', 'accordions'),\n",
       "              ('Cob', 3),\n",
       "              ('IdNumLemma', 253),\n",
       "              ('FlectType', 'P'),\n",
       "              ('TransInfl', '@+s')]),\n",
       " OrderedDict([('IdNum', 464),\n",
       "              ('Word', 'accords'),\n",
       "              ('Cob', 5),\n",
       "              ('IdNumLemma', 247),\n",
       "              ('FlectType', 'P'),\n",
       "              ('TransInfl', '@+s')]),\n",
       " OrderedDict([('IdNum', 465),\n",
       "              ('Word', 'accords'),\n",
       "              ('Cob', 22),\n",
       "              ('IdNumLemma', 248),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', '@+s')])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emw = list(map(parseEMWline,\n",
    "               emw_lines))\n",
    "emw[455:465]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering it for wordforms with inflections of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want wordforms that are \n",
    " - first or third person verbs\n",
    " - and also either present or past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:27.333404Z",
     "start_time": "2019-05-17T01:11:27.329326Z"
    }
   },
   "outputs": [],
   "source": [
    "isPresent       = lambda e: 'e' in e['FlectType']\n",
    "isPast          = lambda e: 'a' in e['FlectType']\n",
    "isFirstPerson   = lambda e: '1' in e['FlectType']\n",
    "isSecondPerson  = lambda e: '2' in e['FlectType']\n",
    "isThirdPerson   = lambda e: '3' in e['FlectType']\n",
    "isParticiple    = lambda e: 'p' in e['FlectType']\n",
    "isNotParticiple = lambda e: not isParticiple(e)\n",
    "isNotPhrasal    = lambda e: not ' ' in e['Word']\n",
    "\n",
    "isOfInterest = lambda e: (isFirstPerson(e) or isThirdPerson(e)) \\\n",
    "                         and (isPresent(e) or isPast(e)) \\\n",
    "                         and isNotPhrasal(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:27.415672Z",
     "start_time": "2019-05-17T01:11:27.334544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24065"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emw_of_interest = list(filter(isOfInterest,\n",
    "                              emw))\n",
    "len(emw_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:27.490593Z",
     "start_time": "2019-05-17T01:11:27.417027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24065"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[131073, 131075, 131081, 131083, 131087, 17, 131089, 131091, 20, 22]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IdNums_of_interest = set(map(lambda e: e['IdNum'],\n",
    "                              emw_of_interest))\n",
    "len(IdNums_of_interest)\n",
    "list(IdNums_of_interest)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:27.537364Z",
     "start_time": "2019-05-17T01:11:27.491995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5985"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[32768, 32770, 32774, 12, 15, 32783, 17, 18, 32789, 25]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IdNumLemmas_of_interest = set(map(lambda e: e['IdNumLemma'],\n",
    "                                  emw_of_interest))\n",
    "len(IdNumLemmas_of_interest)\n",
    "list(IdNumLemmas_of_interest)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:27.543806Z",
     "start_time": "2019-05-17T01:11:27.538758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 25373),\n",
       "              ('Word', 'dissociated'),\n",
       "              ('Cob', 2),\n",
       "              ('IdNumLemma', 12956),\n",
       "              ('FlectType', 'a1S'),\n",
       "              ('TransInfl', '@+d')]),\n",
       " OrderedDict([('IdNum', 25374),\n",
       "              ('Word', 'dissociates'),\n",
       "              ('Cob', 0),\n",
       "              ('IdNumLemma', 12956),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', '@+s')]),\n",
       " OrderedDict([('IdNum', 25385),\n",
       "              ('Word', 'dissolved'),\n",
       "              ('Cob', 28),\n",
       "              ('IdNumLemma', 12964),\n",
       "              ('FlectType', 'a1S'),\n",
       "              ('TransInfl', '@+d')]),\n",
       " OrderedDict([('IdNum', 25386),\n",
       "              ('Word', 'dissolves'),\n",
       "              ('Cob', 39),\n",
       "              ('IdNumLemma', 12964),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', '@+s')]),\n",
       " OrderedDict([('IdNum', 25393),\n",
       "              ('Word', 'dissuaded'),\n",
       "              ('Cob', 3),\n",
       "              ('IdNumLemma', 12968),\n",
       "              ('FlectType', 'a1S'),\n",
       "              ('TransInfl', '@+d')]),\n",
       " OrderedDict([('IdNum', 25394),\n",
       "              ('Word', 'dissuades'),\n",
       "              ('Cob', 3),\n",
       "              ('IdNumLemma', 12968),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', '@+s')]),\n",
       " OrderedDict([('IdNum', 25404),\n",
       "              ('Word', 'distanced'),\n",
       "              ('Cob', 2),\n",
       "              ('IdNumLemma', 12975),\n",
       "              ('FlectType', 'a1S'),\n",
       "              ('TransInfl', '@+d')]),\n",
       " OrderedDict([('IdNum', 25406),\n",
       "              ('Word', 'distances'),\n",
       "              ('Cob', 0),\n",
       "              ('IdNumLemma', 12975),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', '@+s')]),\n",
       " OrderedDict([('IdNum', 25417),\n",
       "              ('Word', 'distempered'),\n",
       "              ('Cob', 1),\n",
       "              ('IdNumLemma', 12983),\n",
       "              ('FlectType', 'a1S'),\n",
       "              ('TransInfl', '@+ed')]),\n",
       " OrderedDict([('IdNum', 25419),\n",
       "              ('Word', 'distempers'),\n",
       "              ('Cob', 0),\n",
       "              ('IdNumLemma', 12983),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', '@+s')])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emw_of_interest[3255:3265]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:27.553392Z",
     "start_time": "2019-05-17T01:11:27.545065Z"
    }
   },
   "outputs": [],
   "source": [
    "def allWordforms_with_lemma(IdNumLemma, emw_entries, present=None, firstPerson=None):\n",
    "    baseline_matches = [e for e in emw_entries if e['IdNumLemma'] == IdNumLemma]\n",
    "    if present is None and firstPerson is None:\n",
    "        return baseline_matches\n",
    "    if present is not None:\n",
    "        if present:\n",
    "            tense_filtered = list(filter(isPresent,\n",
    "                                         baseline_matches))\n",
    "        else:\n",
    "            tense_filtered = list(filter(isPast,\n",
    "                                         baseline_matches))\n",
    "    else:\n",
    "        tense_filtered = baseline_matches\n",
    "    if firstPerson is not None:\n",
    "        if firstPerson:\n",
    "            person_filtered = list(filter(isFirstPerson,\n",
    "                                          tense_filtered))\n",
    "        else:\n",
    "            person_filtered = list(filter(isThirdPerson,\n",
    "                                          tense_filtered))\n",
    "    else:\n",
    "        person_filtered = tense_filtered\n",
    "    return person_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering `emw` for just those lemmas with *all* inflections of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With respect to the two morphosyntactic properties previously mentioned and the four possible combinations of values for those properties, we only want wordforms for lemmas where *all four* possible inflections of interest are documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:11:27.561524Z",
     "start_time": "2019-05-17T01:11:27.554813Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemma_has_inflections_of_interest(IdNumLemma, emw_entries):\n",
    "    entries={\n",
    "        \"1p.pres\":allWordforms_with_lemma(IdNumLemma, emw_entries, present=True, firstPerson=True),\n",
    "        \"1p.past\":allWordforms_with_lemma(IdNumLemma, emw_entries, present=False, firstPerson=True),\n",
    "        \"3p.pres\":allWordforms_with_lemma(IdNumLemma, emw_entries, present=True, firstPerson=False),\n",
    "        \"3p.past\":allWordforms_with_lemma(IdNumLemma, emw_entries, present=False, firstPerson=False)\n",
    "    }\n",
    "    \n",
    "    for k in entries:\n",
    "        if len(entries[k]) == 0:\n",
    "            print(\"IdNumLemma {0} has no entries for inflection {1}\".format(IdNumLemma, k))\n",
    "    if any([len(entries[k]) == 0 for k in entries]):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:12:05.870699Z",
     "start_time": "2019-05-17T01:11:54.801714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5985"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1406s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1564s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 392 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:    1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdNumLemma 3831 has no entries for inflection 1p.past\n",
      "IdNumLemma 3831 has no entries for inflection 3p.pres\n",
      "IdNumLemma 3831 has no entries for inflection 3p.past\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 676 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 884 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 992 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1108 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1348 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1472 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1604 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1736 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1876 tasks      | elapsed:    3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdNumLemma 41818 has no entries for inflection 1p.past\n",
      "IdNumLemma 41818 has no entries for inflection 3p.past\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2016 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2164 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2312 tasks      | elapsed:    4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdNumLemma 11151 has no entries for inflection 1p.past\n",
      "IdNumLemma 11151 has no entries for inflection 3p.pres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2468 tasks      | elapsed:    4.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdNumLemma 11151 has no entries for inflection 3p.past\n",
      "IdNumLemma 44435 has no entries for inflection 1p.pres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2624 tasks      | elapsed:    4.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdNumLemma 44435 has no entries for inflection 3p.pres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2788 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2952 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3124 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3296 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3476 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3656 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3844 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4032 tasks      | elapsed:    7.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdNumLemma 49753 has no entries for inflection 3p.pres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4228 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4424 tasks      | elapsed:    7.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdNumLemma 52098 has no entries for inflection 1p.past\n",
      "IdNumLemma 52098 has no entries for inflection 3p.past\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4628 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4832 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5044 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 5256 tasks      | elapsed:    9.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdNumLemma 28326 has no entries for inflection 1p.past\n",
      "IdNumLemma 28326 has no entries for inflection 3p.past\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5476 tasks      | elapsed:    9.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdNumLemma 29546 has no entries for inflection 1p.past\n",
      "IdNumLemma 29546 has no entries for inflection 3p.past\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5696 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5985 out of 5985 | elapsed:   10.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5977"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IdNumLemmas_of_interest)\n",
    "\n",
    "#takes ~3.5m on Wittgenstein\n",
    "# IdNumLemmas_of_interest_with_all_inflections = list(filter(lambda IdNumLemma: lemma_has_inflections_of_interest(IdNumLemma, emw_of_interest),\n",
    "#                                                            IdNumLemmas_of_interest))\n",
    "\n",
    "\n",
    "# takes 11s\n",
    "def include_IdNumLemma(IdNumLemma):\n",
    "    return lemma_has_inflections_of_interest(IdNumLemma, emw_of_interest)\n",
    "IdNumLemma_mask = par(delayed(include_IdNumLemma)(IdNumLemma) for IdNumLemma in IdNumLemmas_of_interest)\n",
    "\n",
    "IdNumLemmas_of_interest_with_all_inflections = list(compress(IdNumLemmas_of_interest, IdNumLemma_mask))\n",
    "\n",
    "len(IdNumLemmas_of_interest_with_all_inflections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:12:23.061267Z",
     "start_time": "2019-05-17T01:12:22.964147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 101737),\n",
       "              ('Word', 'beware'),\n",
       "              ('Cob', 23),\n",
       "              ('IdNumLemma', 3831),\n",
       "              ('FlectType', 'e1S'),\n",
       "              ('TransInfl', '@')])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 114492),\n",
       "              ('Word', 'should'),\n",
       "              ('Cob', 3552),\n",
       "              ('IdNumLemma', 41818),\n",
       "              ('FlectType', 'e1S'),\n",
       "              ('TransInfl', '@')]),\n",
       " OrderedDict([('IdNum', 148394),\n",
       "              ('Word', 'should'),\n",
       "              ('Cob', 3552),\n",
       "              ('IdNumLemma', 41818),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', 'IRR')])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 104314),\n",
       "              ('Word', 'daresay'),\n",
       "              ('Cob', 21),\n",
       "              ('IdNumLemma', 11151),\n",
       "              ('FlectType', 'e1S'),\n",
       "              ('TransInfl', '@')])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 86310),\n",
       "              ('Word', 'stove'),\n",
       "              ('Cob', 1),\n",
       "              ('IdNumLemma', 44435),\n",
       "              ('FlectType', 'a1S')]),\n",
       " OrderedDict([('IdNum', 132579),\n",
       "              ('Word', 'stove'),\n",
       "              ('Cob', 1),\n",
       "              ('IdNumLemma', 44435),\n",
       "              ('FlectType', 'a3S')])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 95574),\n",
       "              ('Word', 'used'),\n",
       "              ('Cob', 554),\n",
       "              ('IdNumLemma', 49753),\n",
       "              ('FlectType', 'a1S'),\n",
       "              ('TransInfl', '@+d')]),\n",
       " OrderedDict([('IdNum', 117159),\n",
       "              ('Word', 'use'),\n",
       "              ('Cob', 0),\n",
       "              ('IdNumLemma', 49753),\n",
       "              ('FlectType', 'e1S'),\n",
       "              ('TransInfl', '@')]),\n",
       " OrderedDict([('IdNum', 134093),\n",
       "              ('Word', 'used'),\n",
       "              ('Cob', 554),\n",
       "              ('IdNumLemma', 49753),\n",
       "              ('FlectType', 'a3S'),\n",
       "              ('TransInfl', '@+d')])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 99942),\n",
       "              ('Word', 'woulds'),\n",
       "              ('Cob', 0),\n",
       "              ('IdNumLemma', 52098),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', '@+s')]),\n",
       " OrderedDict([('IdNum', 117842),\n",
       "              ('Word', 'would'),\n",
       "              ('Cob', 4612),\n",
       "              ('IdNumLemma', 52098),\n",
       "              ('FlectType', 'e1S'),\n",
       "              ('TransInfl', '@')])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 110064),\n",
       "              ('Word', 'might'),\n",
       "              ('Cob', 1116),\n",
       "              ('IdNumLemma', 28326),\n",
       "              ('FlectType', 'e1S'),\n",
       "              ('TransInfl', '@')]),\n",
       " OrderedDict([('IdNum', 144068),\n",
       "              ('Word', 'might'),\n",
       "              ('Cob', 1116),\n",
       "              ('IdNumLemma', 28326),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', 'IRR')])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('IdNum', 110461),\n",
       "              ('Word', 'must'),\n",
       "              ('Cob', 3304),\n",
       "              ('IdNumLemma', 29546),\n",
       "              ('FlectType', 'e1S'),\n",
       "              ('TransInfl', '@')]),\n",
       " OrderedDict([('IdNum', 144452),\n",
       "              ('Word', 'must'),\n",
       "              ('Cob', 3304),\n",
       "              ('IdNumLemma', 29546),\n",
       "              ('FlectType', 'e3S'),\n",
       "              ('TransInfl', 'IRR')])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWordforms_with_lemma(3831, emw_of_interest)\n",
    "allWordforms_with_lemma(41818, emw_of_interest)\n",
    "allWordforms_with_lemma(11151, emw_of_interest)\n",
    "allWordforms_with_lemma(44435, emw_of_interest)\n",
    "allWordforms_with_lemma(49753, emw_of_interest)\n",
    "allWordforms_with_lemma(52098, emw_of_interest)\n",
    "allWordforms_with_lemma(28326, emw_of_interest)\n",
    "allWordforms_with_lemma(29546, emw_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:16:50.437743Z",
     "start_time": "2019-05-17T01:15:58.409543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24065"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24050"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emw_of_interest)\n",
    "\n",
    "# takes ~50s on wittgenstein\n",
    "emw_of_interest_with_all_inflections = list(chain.from_iterable([allWordforms_with_lemma(IdNumLemma, emw_of_interest) \n",
    "                                                                 for IdNumLemma in IdNumLemmas_of_interest_with_all_inflections]))\n",
    "\n",
    "# takes >>50s\n",
    "# emw_of_interest_with_all_inflections = par(delayed(allWordforms_with_lemma)(IdNumLemma, emw_of_interest)\n",
    "#                                            for IdNumLemma in IdNumLemmas_of_interest_with_all_inflections)\n",
    "# emw_of_interest_with_all_inflections = list(chain.from_iterable(emw_of_interest_with_all_inflections))\n",
    "\n",
    "len(emw_of_interest_with_all_inflections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `tsv` file with rows of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any lemma with multiple wordforms for a given inflection, we will take the wordform for that inflection with the highest frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:16:50.447045Z",
     "start_time": "2019-05-17T01:16:50.439559Z"
    }
   },
   "outputs": [],
   "source": [
    "def createRows(IdNumLemma, emw_entries):\n",
    "    first_person_present_entries = allWordforms_with_lemma(IdNumLemma, emw_entries, present=True, firstPerson=True)\n",
    "    first_person_past_entries    = allWordforms_with_lemma(IdNumLemma, emw_entries, present=False, firstPerson=True)\n",
    "    third_person_present_entries = allWordforms_with_lemma(IdNumLemma, emw_entries, present=True, firstPerson=False)\n",
    "    third_person_past_entries    = allWordforms_with_lemma(IdNumLemma, emw_entries, present=False, firstPerson=False)\n",
    "    \n",
    "    assert len(first_person_present_entries) > 0, \"IdNumLemma {0} has no entries for 1p.pres\".format(IdNumLemma)\n",
    "    assert len(first_person_past_entries) > 0, \"IdNumLemma {0} has no entries for 1p.past\".format(IdNumLemma)\n",
    "    assert len(third_person_present_entries) > 0, \"IdNumLemma {0} has no entries for 3p.pres\".format(IdNumLemma)\n",
    "    assert len(third_person_past_entries) > 0, \"IdNumLemma {0} has no entries for 3p.past\".format(IdNumLemma)\n",
    "    \n",
    "    fp_pres_word = sorted(first_person_present_entries, key=lambda d: d['Cob'], reverse=True)[0]['Word']\n",
    "    fp_past_word = sorted(first_person_past_entries, key=lambda d: d['Cob'], reverse=True)[0]['Word']\n",
    "    tp_pres_word = sorted(third_person_present_entries, key=lambda d: d['Cob'], reverse=True)[0]['Word']\n",
    "    tp_past_word = sorted(third_person_past_entries, key=lambda d: d['Cob'], reverse=True)[0]['Word']\n",
    "    if fp_past_word != tp_past_word:\n",
    "        print(\"1p.pst vs. 3p.pst = {0} vs. {1}\".format(fp_past_word, tp_past_word))\n",
    "    # return {'1p.pres':first_person_present_entries,\n",
    "    #         '1p.past':first_person_past_entries,\n",
    "    #         '3p.pres':third_person_present_entries,\n",
    "    #         '3p.past':third_person_past_entries}\n",
    "    return OrderedDict({\n",
    "            '1p.prs':fp_pres_word,\n",
    "            '1p.pst':fp_past_word,\n",
    "            '3p.prs':tp_pres_word,\n",
    "            '3p.pst':tp_past_word\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:17:43.394249Z",
     "start_time": "2019-05-17T01:17:31.764616Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1358s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1767s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 392 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 676 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 884 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 992 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1108 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1348 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1472 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1604 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1736 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1876 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2016 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2164 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2312 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2468 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2624 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2788 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2952 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3124 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3296 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3476 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3656 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3844 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4032 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4228 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4424 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4628 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4832 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5044 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 5256 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 5476 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 5696 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 5977 out of 5977 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5977"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('1p.prs', 'pauperize'),\n",
       "             ('1p.pst', 'pauperized'),\n",
       "             ('3p.prs', 'pauperizes'),\n",
       "             ('3p.pst', 'pauperized')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes ~4m on wittgenstein\n",
    "# rows_of_interest = list(map(lambda IdNumLemma: createRows(IdNumLemma, emw_of_interest_with_all_inflections),\n",
    "#                             IdNumLemmas_of_interest_with_all_inflections))\n",
    "\n",
    "# takes 11s on wittgenstein\n",
    "def toExportableRow(IdNumLemma):\n",
    "    return createRows(IdNumLemma, emw_of_interest_with_all_inflections)\n",
    "rows_of_interest = par(delayed(toExportableRow)(IdNumLemma) \n",
    "                       for IdNumLemma in IdNumLemmas_of_interest_with_all_inflections)\n",
    "\n",
    "len(rows_of_interest)\n",
    "rows_of_interest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:04.176074Z",
     "start_time": "2019-05-17T01:18:04.173056Z"
    }
   },
   "outputs": [],
   "source": [
    "chdir(repo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:04.743948Z",
     "start_time": "2019-05-17T01:18:04.741345Z"
    }
   },
   "outputs": [],
   "source": [
    "morph_db = rows_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:06.398831Z",
     "start_time": "2019-05-17T01:18:06.336395Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"english-verbs-orth.tsv\", 'w', newline='', encoding='utf-8') as tsvfile:\n",
    "    writer = csv.DictWriter(tsvfile, delimiter='\\t', fieldnames=['1p.prs','1p.pst','3p.prs','3p.pst'], quoting=csv.QUOTE_NONE, quotechar='@')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(morph_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:09.084086Z",
     "start_time": "2019-05-17T01:18:08.278677Z"
    }
   },
   "outputs": [],
   "source": [
    "get_orth_wordforms = lambda row: set(row.values())\n",
    "orthographic_wordforms = union(map(get_orth_wordforms, \n",
    "                                   rows_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substituting orthographic forms for transcriptions from the CMU pronouncing dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The copy of the CMU dictionary used here was generated as described at https://github.com/emeinhardt/cmu-ipa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:11.575296Z",
     "start_time": "2019-05-17T01:18:11.573185Z"
    }
   },
   "outputs": [],
   "source": [
    "transcription_lexicon_fn = 'cmudict-0.7b_IPA_destressed.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:14.546589Z",
     "start_time": "2019-05-17T01:18:13.948916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133854"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['Orthography', 'Transcription'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Orthography', '!EXCLAMATION-POINT'),\n",
       "             ('Transcription', '.k.s.k.l..m.e...n.p..n.t')])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_in = []\n",
    "with open(transcription_lexicon_fn, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    my_reader = csv.DictReader(csvfile, delimiter='\\t', quoting=csv.QUOTE_NONE, quotechar='@')\n",
    "    for row in my_reader:\n",
    "        #print(row)\n",
    "        lexicon_in.append(row)\n",
    "\n",
    "len(lexicon_in)\n",
    "lexicon_in[0].keys()\n",
    "lexicon_in[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:17.013371Z",
     "start_time": "2019-05-17T01:18:16.970856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133854"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_orthographic_wordforms_lc = set(map(lambda row: row['Orthography'].lower(),\n",
    "                                                  lexicon_in))\n",
    "len(transcription_orthographic_wordforms_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:18.943866Z",
     "start_time": "2019-05-17T01:18:18.920362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5139"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'attorn',\n",
       " 'sensitizes',\n",
       " 'moil',\n",
       " 'poniard',\n",
       " 'touch-type',\n",
       " 'confab',\n",
       " 'eviscerates',\n",
       " 'conciliate',\n",
       " 'elided',\n",
       " 'libelled',\n",
       " 'unfurls',\n",
       " 'sulks',\n",
       " 'disinters',\n",
       " 'over-exerts',\n",
       " 'splodge',\n",
       " 'crenellate',\n",
       " 'velarize',\n",
       " 'undersells',\n",
       " 'whops',\n",
       " 'de-escalate',\n",
       " 'waddles',\n",
       " 'swinge',\n",
       " 'miscalled',\n",
       " 'redacts',\n",
       " 'macadamize',\n",
       " 'outstayed',\n",
       " 'placates',\n",
       " 'stupefies',\n",
       " 'desalinize',\n",
       " 'machinate',\n",
       " 'flavoured',\n",
       " 'disrobed',\n",
       " 'rehabilitates',\n",
       " 'metabolized',\n",
       " 'tousled',\n",
       " 'farrowed',\n",
       " 'levitates',\n",
       " 'sermonizes',\n",
       " 'misreads',\n",
       " 'defames',\n",
       " 'tousle',\n",
       " 'sculled',\n",
       " 'composts',\n",
       " 'shinned',\n",
       " 'dappled',\n",
       " 'embitters',\n",
       " 'slenderized',\n",
       " 'mistranslate',\n",
       " 'adduces',\n",
       " 'debark',\n",
       " 'demonetizes',\n",
       " 'oxygenized',\n",
       " 'barbarized',\n",
       " 'orated',\n",
       " 'reconstructs',\n",
       " 'diffracted',\n",
       " 'gormandizes',\n",
       " 'hie',\n",
       " 'droops',\n",
       " 'cerebrates',\n",
       " 'congratulates',\n",
       " 'prinks',\n",
       " 'berthed',\n",
       " 'disarranged',\n",
       " 'soldered',\n",
       " 'cohabited',\n",
       " 'interpellated',\n",
       " 'bumbled',\n",
       " 'dry-cleaned',\n",
       " 'decoke',\n",
       " 'pottered',\n",
       " 'squealed',\n",
       " 'ad-libbed',\n",
       " 'vilifies',\n",
       " 'alloyed',\n",
       " 'roller-skated',\n",
       " 'scythed',\n",
       " 'smelted',\n",
       " 'munches',\n",
       " 'descaled',\n",
       " 'miscarries',\n",
       " 'slurps',\n",
       " 'enfolds',\n",
       " 'afforested',\n",
       " 'bleaches',\n",
       " 'meddled',\n",
       " 'relaid',\n",
       " 'moulted',\n",
       " 'stammered',\n",
       " 'interposes',\n",
       " 'hoed',\n",
       " 'surtaxed',\n",
       " 'deodorizes',\n",
       " 'sentimentalizes',\n",
       " 'babied',\n",
       " 'amortizes',\n",
       " 'postulated',\n",
       " 'routs',\n",
       " 'sequestrate',\n",
       " 'verbalizes',\n",
       " 'snugs',\n",
       " 'co-ordinates',\n",
       " 'reactivates',\n",
       " 'affranchised',\n",
       " 'jemmy',\n",
       " 'tousles',\n",
       " 'redresses',\n",
       " 'blazons',\n",
       " 'desalted',\n",
       " 'greyed',\n",
       " 'capsizes',\n",
       " 'sledded',\n",
       " 'depute',\n",
       " 'resounds',\n",
       " 'mass-produce',\n",
       " 'oversteer',\n",
       " 'chatters',\n",
       " 'drizzled',\n",
       " 'understudied',\n",
       " 'overbear',\n",
       " 'moulders',\n",
       " 'gawped',\n",
       " 'dismount',\n",
       " 'remounted',\n",
       " 'collectivizes',\n",
       " 'clumped',\n",
       " 'manicures',\n",
       " 'middled',\n",
       " 'abstains',\n",
       " 'debone',\n",
       " 'mercerized',\n",
       " 'clamours',\n",
       " 'freighted',\n",
       " 'passivized',\n",
       " 'blab',\n",
       " 'reproached',\n",
       " 'misapprehended',\n",
       " 'humps',\n",
       " 'resurfaces',\n",
       " 'beseemed',\n",
       " 'snugged',\n",
       " 'about-face',\n",
       " 'imaged',\n",
       " 'over-produced',\n",
       " 'satirized',\n",
       " 'bugled',\n",
       " 'miaous',\n",
       " 'degauss',\n",
       " 'window-shop',\n",
       " 'conglomerated',\n",
       " 'appose',\n",
       " 'unsaddled',\n",
       " 'misapprehends',\n",
       " 'miaou',\n",
       " 'evanesces',\n",
       " 'decimalize',\n",
       " 'loots',\n",
       " 'trespasses',\n",
       " 'subsists',\n",
       " 'dislodges',\n",
       " 'belabour',\n",
       " 'nickelled',\n",
       " 'contraindicated',\n",
       " 'mistimed',\n",
       " 'blethers',\n",
       " 'congregates',\n",
       " 'disestablished',\n",
       " 'jumbles',\n",
       " 'conceptualize',\n",
       " 'eavesdrops',\n",
       " 'yakked',\n",
       " 'splodged',\n",
       " 'sledged',\n",
       " 'roves',\n",
       " 'impends',\n",
       " 'remarries',\n",
       " 'appends',\n",
       " 'adumbrate',\n",
       " 'verbalized',\n",
       " 'scintillate',\n",
       " 'cements',\n",
       " 'speechified',\n",
       " 'trussed',\n",
       " 'deflower',\n",
       " 'double-glazed',\n",
       " 'seethed',\n",
       " 'swaggered',\n",
       " 'disinfest',\n",
       " 'romped',\n",
       " 'chaperoned',\n",
       " 'prickled',\n",
       " 'mottle',\n",
       " 'despond',\n",
       " 'blench',\n",
       " 'bethought',\n",
       " 'clewed',\n",
       " 'de-ice',\n",
       " 'pomades',\n",
       " 'natters',\n",
       " 'nonplus',\n",
       " 'wiggles',\n",
       " 'reflated',\n",
       " 'variegates',\n",
       " 'enthuses',\n",
       " 'snookers',\n",
       " 'refuelled',\n",
       " 'sloshed',\n",
       " 'skedaddled',\n",
       " 'transship',\n",
       " 'sopped',\n",
       " 'conflated',\n",
       " 'misnames',\n",
       " 'manured',\n",
       " 'miff',\n",
       " 'rubbernecks',\n",
       " 'fructify',\n",
       " 'romanticizes',\n",
       " 'bleated',\n",
       " 'vegetated',\n",
       " 'parleyed',\n",
       " 'dynamited',\n",
       " 'bedaubed',\n",
       " 'interlards',\n",
       " 'shrined',\n",
       " 'outstays',\n",
       " 'chaperons',\n",
       " 'conciliates',\n",
       " 'prostituted',\n",
       " 'pitchforked',\n",
       " 'apostrophize',\n",
       " 'clanged',\n",
       " 'joshed',\n",
       " 'primps',\n",
       " 'judders',\n",
       " 'eructates',\n",
       " 'frivols',\n",
       " 'canoodle',\n",
       " 'betakes',\n",
       " 'belay',\n",
       " 'overcapitalizes',\n",
       " 'remonstrates',\n",
       " 'lionizes',\n",
       " 'surcharged',\n",
       " 'disaffects',\n",
       " 'prink',\n",
       " 'flummoxes',\n",
       " 'conciliated',\n",
       " 'whets',\n",
       " 'tie-dye',\n",
       " 'keelhaul',\n",
       " 'demarcate',\n",
       " 'devitalized',\n",
       " 'frizzle',\n",
       " 'disinfests',\n",
       " 'thudded',\n",
       " 'frizzles',\n",
       " 'anneals',\n",
       " 'unwinds',\n",
       " 'de-escalates',\n",
       " 'co-opts',\n",
       " 'suckled',\n",
       " 'guillotined',\n",
       " 'defecated',\n",
       " 'crimed',\n",
       " 'altercated',\n",
       " 'electioneered',\n",
       " 'captained',\n",
       " 'unloosed',\n",
       " 'countermarched',\n",
       " 'situates',\n",
       " 'adjured',\n",
       " 'refashion',\n",
       " 'educe',\n",
       " 'canonizes',\n",
       " 'discompose',\n",
       " 'confabbed',\n",
       " 'churched',\n",
       " 'transmutes',\n",
       " 'poled',\n",
       " 'maroons',\n",
       " 'over-values',\n",
       " 'deodorized',\n",
       " 'disbelieves',\n",
       " 'empanelled',\n",
       " 'philosophizes',\n",
       " 'gladdens',\n",
       " 'postmarks',\n",
       " 'retaliates',\n",
       " 'slakes',\n",
       " 'unpick',\n",
       " 'enjoins',\n",
       " 'outrank',\n",
       " 'recharges',\n",
       " 'disburdened',\n",
       " 'forbear',\n",
       " 'moult',\n",
       " 'blabs',\n",
       " 'rehoused',\n",
       " 'outbalances',\n",
       " 'prettify',\n",
       " 'reflates',\n",
       " 'crayoned',\n",
       " 'beggared',\n",
       " 'guillotines',\n",
       " 'tergiversate',\n",
       " 'belly-aches',\n",
       " 'saunters',\n",
       " 'hedgehopped',\n",
       " 'educed',\n",
       " 'motorizes',\n",
       " 'narks',\n",
       " 'interbreeds',\n",
       " 'short-changed',\n",
       " 'propitiates',\n",
       " 'remodels',\n",
       " 'flogs',\n",
       " 'decarbonizes',\n",
       " 'botches',\n",
       " 'syringed',\n",
       " 'kenned',\n",
       " 'dismasted',\n",
       " 'confuted',\n",
       " 'ingests',\n",
       " 'streamlines',\n",
       " 'foreordained',\n",
       " 'cambers',\n",
       " 'dishonour',\n",
       " 'disperses',\n",
       " 'splay',\n",
       " 'consigns',\n",
       " 'interlocks',\n",
       " 'plunks',\n",
       " 'booby-trap',\n",
       " 'strutted',\n",
       " 'treed',\n",
       " 'liquidize',\n",
       " 'legalizes',\n",
       " 'belly-ache',\n",
       " 'weltered',\n",
       " 'bethinks',\n",
       " 'clerked',\n",
       " 'freeloaded',\n",
       " 'clanks',\n",
       " 'hybridizes',\n",
       " 'shadowboxes',\n",
       " 'seethes',\n",
       " 'fluoridize',\n",
       " 'prorogued',\n",
       " 'mortise',\n",
       " 'collaborates',\n",
       " 'exorcized',\n",
       " 'inspan',\n",
       " 'blindfolds',\n",
       " 'purees',\n",
       " 'inundates',\n",
       " 'irradiates',\n",
       " 'outwear',\n",
       " 'out-Herods',\n",
       " 'clew',\n",
       " 'cowls',\n",
       " 'swashed',\n",
       " \"fee'd\",\n",
       " 'unbars',\n",
       " 'dandifies',\n",
       " 'subsume',\n",
       " 'burgeons',\n",
       " 're-present',\n",
       " 'extinguishes',\n",
       " 'hybridized',\n",
       " 'over-indulged',\n",
       " 're-echo',\n",
       " 'slavers',\n",
       " 'rethinks',\n",
       " 'contradistinguish',\n",
       " 'overcompensate',\n",
       " 'whirr',\n",
       " 'appliques',\n",
       " 'converges',\n",
       " 'demonetize',\n",
       " 'reline',\n",
       " 'revivified',\n",
       " 'pulsed',\n",
       " 'play-acts',\n",
       " 'dissimulated',\n",
       " 'bumbles',\n",
       " 'vibrated',\n",
       " 'protrudes',\n",
       " 'exteriorize',\n",
       " 'fluoridized',\n",
       " 'over-eat',\n",
       " 'chaffs',\n",
       " 'cupped',\n",
       " 'busies',\n",
       " 'stashes',\n",
       " 'cowered',\n",
       " 'disburdens',\n",
       " 'conserves',\n",
       " 'tingles',\n",
       " 'baptizes',\n",
       " 'mainlines',\n",
       " 'tittle-tattle',\n",
       " 'rubberizes',\n",
       " 'cross-examined',\n",
       " 'bombards',\n",
       " 'skin-dive',\n",
       " 'disembroiled',\n",
       " 'scrimshanked',\n",
       " 'rustled',\n",
       " 'understock',\n",
       " 'transistorizes',\n",
       " 'unionizes',\n",
       " 'effervesces',\n",
       " 'flaked',\n",
       " 'engraft',\n",
       " 'shirks',\n",
       " 'canters',\n",
       " 'jack-knifes',\n",
       " 'freelanced',\n",
       " 'steeps',\n",
       " 'nauseates',\n",
       " 'puttered',\n",
       " 'piques',\n",
       " 'dissembled',\n",
       " 'hypothecated',\n",
       " 'plonk',\n",
       " 'clattered',\n",
       " 'galled',\n",
       " 'mizzled',\n",
       " 'namedrops',\n",
       " 'overawes',\n",
       " 'inflects',\n",
       " 'plashes',\n",
       " 'transshipped',\n",
       " 'calcines',\n",
       " 'itinerates',\n",
       " 'fib',\n",
       " 'plashed',\n",
       " 'pressgang',\n",
       " 'masticates',\n",
       " 'chequered',\n",
       " 'spot-check',\n",
       " 'enamelled',\n",
       " 'colludes',\n",
       " 'phosphoresced',\n",
       " 'prolapsed',\n",
       " 'traffics',\n",
       " 'probates',\n",
       " 'disfrocked',\n",
       " 'revelled',\n",
       " 'refract',\n",
       " 'misruled',\n",
       " 'soft-pedals',\n",
       " 'overcrops',\n",
       " 'soft-pedalled',\n",
       " 'musses',\n",
       " 'deadened',\n",
       " 'pupates',\n",
       " 'coarsened',\n",
       " 'matted',\n",
       " 'welshes',\n",
       " 'gangrenes',\n",
       " 'disafforests',\n",
       " 'attorned',\n",
       " 'excommunicates',\n",
       " 'particularizes',\n",
       " 'globe-trotted',\n",
       " 'panders',\n",
       " 'enfiladed',\n",
       " 'double-declutched',\n",
       " 'befog',\n",
       " 'scrupled',\n",
       " 'disobliged',\n",
       " 'flyblow',\n",
       " 'lollops',\n",
       " 'particularized',\n",
       " 'short-changes',\n",
       " 'snogs',\n",
       " 'superannuates',\n",
       " 'kipped',\n",
       " 'vituperates',\n",
       " 'mashes',\n",
       " 'outbade',\n",
       " 'evanesced',\n",
       " 'dirties',\n",
       " 'rarefies',\n",
       " 'gambols',\n",
       " 'prepays',\n",
       " 'decorates',\n",
       " 'crossbred',\n",
       " 'derogate',\n",
       " 'metricized',\n",
       " 'perambulate',\n",
       " 'unbind',\n",
       " 'trepan',\n",
       " 'psychoanalyse',\n",
       " 'vivifies',\n",
       " 'scorches',\n",
       " 'dissembles',\n",
       " 'pencilled',\n",
       " 'emulsions',\n",
       " 'imprecates',\n",
       " 'fluoresced',\n",
       " 'cross-fertilized',\n",
       " 'festoons',\n",
       " 'detrain',\n",
       " 'convolve',\n",
       " 'frizzes',\n",
       " 'skitters',\n",
       " 'castled',\n",
       " 'leathered',\n",
       " 'double-crossed',\n",
       " 'twanged',\n",
       " 'codded',\n",
       " 'misname',\n",
       " 'chivied',\n",
       " 'tarmacadam',\n",
       " 'conjoins',\n",
       " 'vulgarizes',\n",
       " 'equivocated',\n",
       " 'decimates',\n",
       " 'bestride',\n",
       " 'intercalate',\n",
       " 'kotows',\n",
       " 'mooched',\n",
       " 'underquotes',\n",
       " 'cyclostyles',\n",
       " 'cosh',\n",
       " 'macerates',\n",
       " 'imbibes',\n",
       " 'sledges',\n",
       " 'slanged',\n",
       " 'hived',\n",
       " 'chirrups',\n",
       " 'telegraphs',\n",
       " 'jack-knifed',\n",
       " 'larruped',\n",
       " 'benefices',\n",
       " 'intermingles',\n",
       " 'enamoured',\n",
       " 'velarized',\n",
       " 'constitutionalized',\n",
       " 'furred',\n",
       " 'punted',\n",
       " 'desalinizes',\n",
       " 'unnerves',\n",
       " 'lamed',\n",
       " 'palliated',\n",
       " 'deplane',\n",
       " 'sideswiped',\n",
       " 'abnegate',\n",
       " 'genuflected',\n",
       " 'subdivides',\n",
       " 'soft-soap',\n",
       " 'chain-smokes',\n",
       " 'wrings',\n",
       " 'bowdlerizes',\n",
       " 'besought',\n",
       " 'gallivant',\n",
       " 'apostrophizes',\n",
       " 'countermined',\n",
       " 'touch-types',\n",
       " 'moseyed',\n",
       " 'rustles',\n",
       " 'pole-vaulted',\n",
       " 'enkindle',\n",
       " 'italicizes',\n",
       " 'nickel-plated',\n",
       " 'excruciates',\n",
       " 'cased',\n",
       " 'drowses',\n",
       " 'incapacitates',\n",
       " 'hooped',\n",
       " 'illumine',\n",
       " 'venges',\n",
       " 'squired',\n",
       " 'spiralled',\n",
       " 'snaffled',\n",
       " 'endeavoured',\n",
       " 'clops',\n",
       " 'overcropped',\n",
       " 'stylizes',\n",
       " 'smouldered',\n",
       " 'bottle-fed',\n",
       " 'chequers',\n",
       " 'slaved',\n",
       " 'reforests',\n",
       " 'disendow',\n",
       " 'razes',\n",
       " 'stridulates',\n",
       " 'skivvied',\n",
       " 'slobbered',\n",
       " 'pearled',\n",
       " 'americanizes',\n",
       " 'enfilade',\n",
       " 'lanced',\n",
       " 'elide',\n",
       " 'swathes',\n",
       " 'pomade',\n",
       " 'regurgitates',\n",
       " 'annealed',\n",
       " 'supplicates',\n",
       " 'parleys',\n",
       " 'joggles',\n",
       " 'tutted',\n",
       " 'over-produces',\n",
       " 'auscultated',\n",
       " 'immigrates',\n",
       " 'begrudged',\n",
       " 'canoodles',\n",
       " 'uglifies',\n",
       " 'heliographs',\n",
       " 'palsied',\n",
       " 'snick',\n",
       " 'retouch',\n",
       " 'tars',\n",
       " 'atoned',\n",
       " 'enwraps',\n",
       " 'discomfit',\n",
       " 'ululate',\n",
       " 'admixes',\n",
       " 'swivelled',\n",
       " 'counterpoise',\n",
       " 'undocked',\n",
       " 'derequisition',\n",
       " 'braises',\n",
       " 'manumitted',\n",
       " 'aerated',\n",
       " 'annunciates',\n",
       " 'protuberated',\n",
       " 'unbosomed',\n",
       " 'dethrones',\n",
       " 'boozed',\n",
       " 'disorientate',\n",
       " 'misdemeans',\n",
       " 'mishits',\n",
       " 'power-dives',\n",
       " 'revivify',\n",
       " 'sasses',\n",
       " 'negatived',\n",
       " 'galumph',\n",
       " 'repoints',\n",
       " 'confabs',\n",
       " 'breathalysed',\n",
       " 'coursed',\n",
       " 'miscued',\n",
       " 'unsex',\n",
       " 'sunbathed',\n",
       " 'curtained',\n",
       " 'blandishes',\n",
       " 'atones',\n",
       " 'splotched',\n",
       " 'sleeks',\n",
       " 'geld',\n",
       " 'outdates',\n",
       " 'refracts',\n",
       " 'sired',\n",
       " 'doddered',\n",
       " 'renovates',\n",
       " 'prepossesses',\n",
       " 'shrives',\n",
       " 'tippled',\n",
       " 'granulate',\n",
       " 'arced',\n",
       " 'mends',\n",
       " 'ululated',\n",
       " 'circularizes',\n",
       " 'overstocks',\n",
       " 'decolonized',\n",
       " 'towelled',\n",
       " 'swagged',\n",
       " 'disrobes',\n",
       " 'banters',\n",
       " 'popularizes',\n",
       " 'relined',\n",
       " 'dices',\n",
       " 'dins',\n",
       " 'connived',\n",
       " 'gawks',\n",
       " 'unbar',\n",
       " 'kowtowed',\n",
       " 'desalinized',\n",
       " 'velarizes',\n",
       " 'standardizes',\n",
       " 'slinks',\n",
       " 'coaled',\n",
       " 'scowls',\n",
       " 'denunciates',\n",
       " 'fricassee',\n",
       " 'nasalizes',\n",
       " 'embargos',\n",
       " 'sidetracks',\n",
       " 'turfs',\n",
       " 'cocooned',\n",
       " 'dialled',\n",
       " 'fazes',\n",
       " 'smirked',\n",
       " 'overlies',\n",
       " 'swigs',\n",
       " 'umpired',\n",
       " 'signalized',\n",
       " 'double-checked',\n",
       " 'slews',\n",
       " 'sulphuretted',\n",
       " 'harrows',\n",
       " 'centralizes',\n",
       " 'enwrap',\n",
       " 'crocks',\n",
       " 'reproofs',\n",
       " 'jollifies',\n",
       " 'cods',\n",
       " 'assayed',\n",
       " 'affianced',\n",
       " 'fricassees',\n",
       " 'jewelled',\n",
       " 'macadamized',\n",
       " 'trawled',\n",
       " 'vouchsafes',\n",
       " 'derate',\n",
       " 'coddles',\n",
       " 'effectuates',\n",
       " 'surmounts',\n",
       " 'wheezed',\n",
       " 'calender',\n",
       " 'intertwines',\n",
       " 'barnstormed',\n",
       " 'profiteered',\n",
       " 'mercerize',\n",
       " 'gawps',\n",
       " 'iterated',\n",
       " 'skives',\n",
       " 'yapped',\n",
       " 'cleanses',\n",
       " 'limed',\n",
       " 'palavers',\n",
       " 'reeducated',\n",
       " 'airdropped',\n",
       " 'domineers',\n",
       " 'begrime',\n",
       " 'narked',\n",
       " 'untangles',\n",
       " 'syllabicates',\n",
       " 'lambed',\n",
       " 'tiptoes',\n",
       " 'visualizes',\n",
       " 'belly-laugh',\n",
       " 'fructifies',\n",
       " 'instate',\n",
       " 'recants',\n",
       " 'oppugn',\n",
       " 'palatalize',\n",
       " 'manifolds',\n",
       " 'sellotape',\n",
       " 'unhorse',\n",
       " 'orate',\n",
       " 'cross-refers',\n",
       " 'miaoued',\n",
       " 'blenches',\n",
       " 'exculpates',\n",
       " 'laicize',\n",
       " 'dazzles',\n",
       " 'atomized',\n",
       " 'adventured',\n",
       " 'tootled',\n",
       " 'disinherits',\n",
       " 'repaints',\n",
       " 'pierces',\n",
       " 'corned',\n",
       " 'palatalized',\n",
       " 'pecks',\n",
       " 'disenfranchises',\n",
       " 'hurtled',\n",
       " 'caroused',\n",
       " 'scrimps',\n",
       " 'honeycombs',\n",
       " 'boobed',\n",
       " 'shovelled',\n",
       " 'womanizes',\n",
       " 'subtracts',\n",
       " 'debited',\n",
       " 'uncoupled',\n",
       " 'publicizes',\n",
       " 'alliterates',\n",
       " 'excepts',\n",
       " 'resuscitates',\n",
       " 'prerecords',\n",
       " 'depredates',\n",
       " 'vandalizes',\n",
       " 'distils',\n",
       " 'contravened',\n",
       " 'nonplusses',\n",
       " 'unlooses',\n",
       " 'peregrinate',\n",
       " 'uglified',\n",
       " 'jerry-build',\n",
       " 'contradistinguished',\n",
       " 'netts',\n",
       " 'prettified',\n",
       " 'salified',\n",
       " 'delimit',\n",
       " 'havers',\n",
       " 'bedews',\n",
       " 'disport',\n",
       " 'skims',\n",
       " 'chloroformed',\n",
       " 'scrag',\n",
       " 'disendows',\n",
       " 'spiritualize',\n",
       " 'predeceases',\n",
       " 'electrocutes',\n",
       " 'whined',\n",
       " 'constitutionalizes',\n",
       " 'urbanizes',\n",
       " 'christens',\n",
       " 'befogs',\n",
       " 'bootlegged',\n",
       " 'rubbished',\n",
       " 'scandalizes',\n",
       " 'flatters',\n",
       " 'tenses',\n",
       " 'reduplicate',\n",
       " 'clanked',\n",
       " 'deplaned',\n",
       " 'cognizes',\n",
       " 'iterate',\n",
       " 'maturates',\n",
       " 'patters',\n",
       " 'indemnifies',\n",
       " 'sightsees',\n",
       " 'mimeographed',\n",
       " 'discommode',\n",
       " 'emboldens',\n",
       " 'betokens',\n",
       " 'unburdens',\n",
       " 're-cover',\n",
       " 'deflowered',\n",
       " 'appeases',\n",
       " 'wakened',\n",
       " 'palmed',\n",
       " 'phosphoresces',\n",
       " 'transubstantiates',\n",
       " 'carburet',\n",
       " 'stabled',\n",
       " 'discolour',\n",
       " 'garlanded',\n",
       " 'approbated',\n",
       " 'pre-exists',\n",
       " 'disfavoured',\n",
       " 'trounces',\n",
       " 'regenerates',\n",
       " 'coarsen',\n",
       " 'draggle',\n",
       " 'ejaculated',\n",
       " 'tidies',\n",
       " 'peached',\n",
       " 'shoplifted',\n",
       " 'legitimatized',\n",
       " 'yodels',\n",
       " 'over-cooked',\n",
       " 'thieved',\n",
       " 'freewheel',\n",
       " 'spoliated',\n",
       " 'revenges',\n",
       " 'resounded',\n",
       " 'illume',\n",
       " 'japanned',\n",
       " 'cerebrated',\n",
       " 'tonsured',\n",
       " 'crimsoned',\n",
       " 'copy-edited',\n",
       " 'adjoined',\n",
       " 'purled',\n",
       " 'skive',\n",
       " 'deforms',\n",
       " 'etiolates',\n",
       " 'masqueraded',\n",
       " 'flitted',\n",
       " 'galumphs',\n",
       " 'replenishes',\n",
       " 'relents',\n",
       " 'muckrakes',\n",
       " 'rustproofed',\n",
       " 'spring-cleans',\n",
       " 'plained',\n",
       " 'dignifies',\n",
       " 'asterisked',\n",
       " 'expatiates',\n",
       " 'affranchises',\n",
       " 'lambast',\n",
       " 'fornicate',\n",
       " 'ejaculates',\n",
       " 'descales',\n",
       " 'trephines',\n",
       " 'instrumented',\n",
       " 'jibs',\n",
       " 'begrudges',\n",
       " 'breathalyse',\n",
       " 'disforest',\n",
       " 'miaowed',\n",
       " 'pestles',\n",
       " 'counterplotted',\n",
       " 'biffs',\n",
       " 'interpolates',\n",
       " 'disrelished',\n",
       " 'gnashes',\n",
       " 'outtalk',\n",
       " 'reefed',\n",
       " 'bestrew',\n",
       " 'interchanged',\n",
       " 'floured',\n",
       " 'respited',\n",
       " 'evinces',\n",
       " 'disbars',\n",
       " 'gurgles',\n",
       " 'coxswains',\n",
       " 'horrifies',\n",
       " 'souse',\n",
       " 'nitpicks',\n",
       " 'pressgangs',\n",
       " 'socializes',\n",
       " 'subsisted',\n",
       " 'outsails',\n",
       " 're-formed',\n",
       " 'misgives',\n",
       " 'encapsulates',\n",
       " 'effaced',\n",
       " 'excogitate',\n",
       " 'glints',\n",
       " 'lances',\n",
       " 'jinxed',\n",
       " 'ratted',\n",
       " 'coagulates',\n",
       " 'bludgeons',\n",
       " 'disfranchised',\n",
       " 'repatriates',\n",
       " 'redoes',\n",
       " 'de-escalated',\n",
       " 'jousted',\n",
       " 'preachified',\n",
       " 'scrunches',\n",
       " 'environed',\n",
       " 'undernourishes',\n",
       " 'caparisons',\n",
       " 'oxidizes',\n",
       " 'crisscrosses',\n",
       " 'straiten',\n",
       " 'co-stars',\n",
       " 'sequestrates',\n",
       " 'refits',\n",
       " 'outbrave',\n",
       " 'bedaub',\n",
       " 'disenchants',\n",
       " 'barbarizes',\n",
       " 'eloped',\n",
       " 'rehears',\n",
       " 'scissored',\n",
       " 'discolours',\n",
       " 'unloosen',\n",
       " 'sovietize',\n",
       " 'debilitates',\n",
       " 'twaddles',\n",
       " 'swats',\n",
       " 'misdemean',\n",
       " 'liaises',\n",
       " 'deranges',\n",
       " 'conked',\n",
       " 'localizes',\n",
       " 'outranks',\n",
       " 'chattered',\n",
       " 'pommels',\n",
       " 'supped',\n",
       " 'tut-tutted',\n",
       " 'deflates',\n",
       " 'surfs',\n",
       " 'poniards',\n",
       " 'pettifogged',\n",
       " 'tittle-tattled',\n",
       " 'circularized',\n",
       " 'repulses',\n",
       " 'cankered',\n",
       " 'enshrines',\n",
       " 'cremates',\n",
       " 'absents',\n",
       " 'intercalated',\n",
       " 'shush',\n",
       " 'evacuates',\n",
       " 're-form',\n",
       " 'scrammed',\n",
       " 'forswears',\n",
       " 'splutter',\n",
       " 'reposed',\n",
       " 'blacklegged',\n",
       " 'clamoured',\n",
       " 'bivouacs',\n",
       " 'boded',\n",
       " 'concertinas',\n",
       " 'guffawed',\n",
       " 'rearmed',\n",
       " 'limbered',\n",
       " 'incubates',\n",
       " 'entreated',\n",
       " ...}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthographic_wordforms_in_morph_db_not_in_transcription_dict = orthographic_wordforms - transcription_orthographic_wordforms_lc\n",
    "len(orthographic_wordforms_in_morph_db_not_in_transcription_dict)\n",
    "orthographic_wordforms_in_morph_db_not_in_transcription_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:29.962214Z",
     "start_time": "2019-05-17T01:18:29.898171Z"
    }
   },
   "outputs": [],
   "source": [
    "lexicon_lc = list(map(lambda row: {'Orthography':row['Orthography'].lower(),\n",
    "                                   'Transcription':row['Transcription']},\n",
    "                      lexicon_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:30.228637Z",
     "start_time": "2019-05-17T01:18:30.224971Z"
    }
   },
   "outputs": [],
   "source": [
    "def findMatchingTranscriptions(orth_lc):\n",
    "    return [r for r in lexicon_lc if r['Orthography'] == orth_lc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning the (orthographic) morphological database with the CMU dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:18:40.930328Z",
     "start_time": "2019-05-17T01:18:40.919901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12588"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignable_wordforms = {w for w in orthographic_wordforms if w in transcription_orthographic_wordforms_lc}\n",
    "len(alignable_wordforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:19:53.047112Z",
     "start_time": "2019-05-17T01:18:41.745254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12588"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignable_wordforms_w_unique_transcription = {w for w in alignable_wordforms if len(findMatchingTranscriptions(w)) == 1}\n",
    "len(alignable_wordforms_w_unique_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:20:08.994262Z",
     "start_time": "2019-05-17T01:20:08.990877Z"
    }
   },
   "outputs": [],
   "source": [
    "def findMatchingTranscription(orth_lc):\n",
    "    return findMatchingTranscriptions(orth_lc)[0]['Transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:20:10.509366Z",
     "start_time": "2019-05-17T01:20:10.496933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d..d'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findMatchingTranscription('did')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:19:53.103555Z",
     "start_time": "2019-05-17T01:19:53.100928Z"
    }
   },
   "outputs": [],
   "source": [
    "def isAlignableRow(morph_db_row):\n",
    "    wordforms = set(morph_db_row.values())\n",
    "    return all([w in alignable_wordforms for w in wordforms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:19:53.117550Z",
     "start_time": "2019-05-17T01:19:53.105049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5977"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3147"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(morph_db)\n",
    "alignable_rows = list(filter(isAlignableRow,\n",
    "                             morph_db))\n",
    "len(alignable_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:20:18.795843Z",
     "start_time": "2019-05-17T01:20:18.792707Z"
    }
   },
   "outputs": [],
   "source": [
    "def alignRow(morph_db_row):\n",
    "    new_row = deepcopy(morph_db_row)\n",
    "    for k in new_row:\n",
    "        new_row[k] = findMatchingTranscription(new_row[k])\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:29:06.997146Z",
     "start_time": "2019-05-17T01:28:54.754597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3147"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1253s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 538 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 592 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 650 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 770 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 832 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 898 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1178 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1252 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1330 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1408 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1490 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1572 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1744 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1834 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1924 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2018 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2112 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2210 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2308 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2410 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2512 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2618 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2724 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2834 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2944 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3084 out of 3147 | elapsed:   11.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3147 out of 3147 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3147"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alignable_rows)\n",
    "\n",
    "# takes ~1m on wittgenstein\n",
    "# aligned_db = list(map(alignRow,\n",
    "#                       alignable_rows))\n",
    "\n",
    "# takes ~11s on wittgenstein\n",
    "aligned_db = par(delayed(alignRow)(row) for row in alignable_rows)\n",
    "\n",
    "len(aligned_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:31:12.183199Z",
     "start_time": "2019-05-17T01:31:12.175388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('1p.prs', 'p..z'),\n",
       "              ('1p.pst', 'p..z.d'),\n",
       "              ('3p.prs', 'p..z..z'),\n",
       "              ('3p.pst', 'p..z.d')]),\n",
       " OrderedDict([('1p.prs', 'p.e.v'),\n",
       "              ('1p.pst', 'p.e.v.d'),\n",
       "              ('3p.prs', 'p.e.v.z'),\n",
       "              ('3p.pst', 'p.e.v.d')]),\n",
       " OrderedDict([('1p.prs', '.b..n.d..n'),\n",
       "              ('1p.pst', '.b..n.d..n.d'),\n",
       "              ('3p.prs', '.b..n.d..n.z'),\n",
       "              ('3p.pst', '.b..n.d..n.d')]),\n",
       " OrderedDict([('1p.prs', 'p.'),\n",
       "              ('1p.pst', 'p..d'),\n",
       "              ('3p.prs', 'p..z'),\n",
       "              ('3p.pst', 'p..d')]),\n",
       " OrderedDict([('1p.prs', '.b.e.t'),\n",
       "              ('1p.pst', '.b.e.t..d'),\n",
       "              ('3p.prs', '.b.e.t.s'),\n",
       "              ('3p.pst', '.b.e.t..d')]),\n",
       " OrderedDict([('1p.prs', 'p..n'),\n",
       "              ('1p.pst', 'p..n.d'),\n",
       "              ('3p.prs', 'p..n.z'),\n",
       "              ('3p.pst', 'p..n.d')]),\n",
       " OrderedDict([('1p.prs', '.b..i.v.i.e.t'),\n",
       "              ('1p.pst', '.b..i.v.i.e.t..d'),\n",
       "              ('3p.prs', '.b..i.v.i.e.t.s'),\n",
       "              ('3p.pst', '.b..i.v.i.e.t..d')]),\n",
       " OrderedDict([('1p.prs', '.b.d..k.e.t'),\n",
       "              ('1p.pst', '.b.d..k.e.t..d'),\n",
       "              ('3p.prs', '.b.d..k.e.t.s'),\n",
       "              ('3p.pst', '.b.d..k.e.t..d')]),\n",
       " OrderedDict([('1p.prs', 'p.e'),\n",
       "              ('1p.pst', 'p.e.d'),\n",
       "              ('3p.prs', 'p.e.z'),\n",
       "              ('3p.pst', 'p.e.d')]),\n",
       " OrderedDict([('1p.prs', '.b.d..k.t'),\n",
       "              ('1p.pst', '.b.d..k.t..d'),\n",
       "              ('3p.prs', '.b.d..k.t.s'),\n",
       "              ('3p.pst', '.b.d..k.t..d')])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_db[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T01:31:51.400947Z",
     "start_time": "2019-05-17T01:31:51.350394Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"english-verbs-phon.tsv\", 'w', newline='', encoding='utf-8') as tsvfile:\n",
    "    writer = csv.DictWriter(tsvfile, delimiter='\\t', fieldnames=['1p.prs','1p.pst','3p.prs','3p.pst'], quoting=csv.QUOTE_NONE, quotechar='@')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(aligned_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
